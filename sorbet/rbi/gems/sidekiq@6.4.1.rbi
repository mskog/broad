# typed: true

# DO NOT EDIT MANUALLY
# This is an autogenerated file for types exported from the `sidekiq` gem.
# Please instead update this file by running `bin/tapioca gem sidekiq`.

# Sidekiq's systemd integration allows Sidekiq to inform systemd:
#  1. when it has successfully started
#  2. when it is starting shutdown
#  3. periodically for a liveness check with a watchdog thread
module Sidekiq
  class << self
    # How frequently Redis should be checked by a random Sidekiq process for
    # scheduled and retriable jobs. Each individual process will take turns by
    # waiting some multiple of this value.
    #
    # See sidekiq/scheduled.rb for an in-depth explanation of this value
    def average_scheduled_poll_interval=(interval); end

    # @yield [@client_chain]
    def client_middleware; end

    # Configuration for Sidekiq client, use like:
    #
    #   Sidekiq.configure_client do |config|
    #     config.redis = { :namespace => 'myapp', :size => 1, :url => 'redis://myhost:8877/0' }
    #   end
    #
    # @yield [_self]
    # @yieldparam _self [Sidekiq] the object that the method was called on
    def configure_client; end

    # Configuration for Sidekiq server, use like:
    #
    #   Sidekiq.configure_server do |config|
    #     config.redis = { :namespace => 'myapp', :size => 25, :url => 'redis://myhost:8877/0' }
    #     config.server_middleware do |chain|
    #       chain.add MyServerHook
    #     end
    #   end
    #
    # @yield [_self]
    # @yieldparam _self [Sidekiq] the object that the method was called on
    def configure_server; end

    # Death handlers are called when all retries for a job have been exhausted and
    # the job dies.  It's the notification to your application
    # that this job will not succeed without manual intervention.
    #
    # Sidekiq.configure_server do |config|
    #   config.death_handlers << ->(job, ex) do
    #   end
    # end
    def death_handlers; end

    def default_server_middleware; end
    def default_worker_options; end
    def default_worker_options=(hash); end
    def dump_json(object); end

    # Register a proc to handle any error which occurs within the Sidekiq process.
    #
    #   Sidekiq.configure_server do |config|
    #     config.error_handlers << proc {|ex,ctx_hash| MyErrorService.notify(ex, ctx_hash) }
    #   end
    #
    # The default error handler logs errors to Sidekiq.logger.
    def error_handlers; end

    def load_json(string); end
    def log_formatter; end
    def log_formatter=(log_formatter); end
    def logger; end
    def logger=(logger); end

    # Register a block to run at a point in the Sidekiq lifecycle.
    # :startup, :quiet or :shutdown are valid events.
    #
    #   Sidekiq.configure_server do |config|
    #     config.on(:shutdown) do
    #       puts "Goodbye cruel world!"
    #     end
    #   end
    #
    # @raise [ArgumentError]
    def on(event, &block); end

    def options; end
    def options=(opts); end

    # @return [Boolean]
    def pro?; end

    # @raise [ArgumentError]
    def redis; end

    def redis=(hash); end
    def redis_info; end
    def redis_pool; end

    # @return [Boolean]
    def server?; end

    # @yield [@server_chain]
    def server_middleware; end

    def strict_args!(mode = T.unsafe(nil)); end
    def â¨â•¯Â°â–¡Â°â©â•¯ï¸µâ”»â”â”»; end
  end
end

class Sidekiq::BasicFetch
  # @raise [ArgumentError]
  # @return [BasicFetch] a new instance of BasicFetch
  def initialize(options); end

  def bulk_requeue(inprogress, options); end

  # Creating the Redis#brpop command takes into account any
  # configured queue weights. By default Redis#brpop returns
  # data from the first queue that has pending elements. We
  # recreate the queue command each time we invoke Redis#brpop
  # to honor weights and avoid queue starvation.
  def queues_cmd; end

  def retrieve_work; end
end

# We want the fetch operation to timeout every few seconds so the thread
# can check if the process is shutting down.
Sidekiq::BasicFetch::TIMEOUT = T.let(T.unsafe(nil), Integer)

class Sidekiq::BasicFetch::UnitOfWork < ::Struct
  def acknowledge; end

  # Returns the value of attribute job
  #
  # @return [Object] the current value of job
  def job; end

  # Sets the attribute job
  #
  # @param value [Object] the value to set the attribute job to.
  # @return [Object] the newly set value
  def job=(_); end

  # Returns the value of attribute queue
  #
  # @return [Object] the current value of queue
  def queue; end

  # Sets the attribute queue
  #
  # @param value [Object] the value to set the attribute queue to.
  # @return [Object] the newly set value
  def queue=(_); end

  def queue_name; end
  def requeue; end

  class << self
    def [](*_arg0); end
    def inspect; end
    def keyword_init?; end
    def members; end
    def new(*_arg0); end
  end
end

class Sidekiq::Client
  include ::Sidekiq::JobUtil

  # Sidekiq::Client normally uses the default Redis pool but you may
  # pass a custom ConnectionPool if you want to shard your
  # Sidekiq jobs across several Redis instances (for scalability
  # reasons, e.g.)
  #
  #   Sidekiq::Client.new(ConnectionPool.new { Redis.new })
  #
  # Generally this is only needed for very large Sidekiq installs processing
  # thousands of jobs per second.  I don't recommend sharding unless you
  # cannot scale any other way (e.g. splitting your app into smaller apps).
  #
  # @return [Client] a new instance of Client
  def initialize(redis_pool = T.unsafe(nil)); end

  # Define client-side middleware:
  #
  #   client = Sidekiq::Client.new
  #   client.middleware do |chain|
  #     chain.use MyClientMiddleware
  #   end
  #   client.push('class' => 'SomeWorker', 'args' => [1,2,3])
  #
  # All client instances default to the globally-defined
  # Sidekiq.client_middleware but you can change as necessary.
  def middleware(&block); end

  # The main method used to push a job to Redis.  Accepts a number of options:
  #
  #   queue - the named queue to use, default 'default'
  #   class - the worker class to call, required
  #   args - an array of simple arguments to the perform method, must be JSON-serializable
  #   at - timestamp to schedule the job (optional), must be Numeric (e.g. Time.now.to_f)
  #   retry - whether to retry this job if it fails, default true or an integer number of retries
  #   backtrace - whether to save any error backtrace, default false
  #
  # If class is set to the class name, the jobs' options will be based on Sidekiq's default
  # worker options. Otherwise, they will be based on the job class's options.
  #
  # Any options valid for a worker class's sidekiq_options are also available here.
  #
  # All options must be strings, not symbols.  NB: because we are serializing to JSON, all
  # symbols in 'args' will be converted to strings.  Note that +backtrace: true+ can take quite a bit of
  # space in Redis; a large volume of failing jobs can start Redis swapping if you aren't careful.
  #
  # Returns a unique Job ID.  If middleware stops the job, nil will be returned instead.
  #
  # Example:
  #   push('queue' => 'my_queue', 'class' => MyWorker, 'args' => ['foo', 1, :bat => 'bar'])
  def push(item); end

  # Push a large number of jobs to Redis. This method cuts out the redis
  # network round trip latency.  I wouldn't recommend pushing more than
  # 1000 per call but YMMV based on network quality, size of job args, etc.
  # A large number of jobs can cause a bit of Redis command processing latency.
  #
  # Takes the same arguments as #push except that args is expected to be
  # an Array of Arrays.  All other keys are duplicated for each job.  Each job
  # is run through the client middleware pipeline and each job gets its own Job ID
  # as normal.
  #
  # Returns an array of the of pushed jobs' jids.  The number of jobs pushed can be less
  # than the number given if the middleware stopped processing for one or more jobs.
  #
  # @raise [ArgumentError]
  def push_bulk(items); end

  # Returns the value of attribute redis_pool.
  def redis_pool; end

  # Sets the attribute redis_pool
  #
  # @param value the value to set the attribute redis_pool to.
  def redis_pool=(_arg0); end

  private

  def atomic_push(conn, payloads); end
  def process_single(worker_class, item); end
  def raw_push(payloads); end

  class << self
    # Resque compatibility helpers.  Note all helpers
    # should go through Worker#client_push.
    #
    # Example usage:
    #   Sidekiq::Client.enqueue(MyWorker, 'foo', 1, :bat => 'bar')
    #
    # Messages are enqueued to the 'default' queue.
    def enqueue(klass, *args); end

    # Example usage:
    #   Sidekiq::Client.enqueue_in(3.minutes, MyWorker, 'foo', 1, :bat => 'bar')
    def enqueue_in(interval, klass, *args); end

    # Example usage:
    #   Sidekiq::Client.enqueue_to(:queue_name, MyWorker, 'foo', 1, :bat => 'bar')
    def enqueue_to(queue, klass, *args); end

    # Example usage:
    #   Sidekiq::Client.enqueue_to_in(:queue_name, 3.minutes, MyWorker, 'foo', 1, :bat => 'bar')
    def enqueue_to_in(queue, interval, klass, *args); end

    def push(item); end
    def push_bulk(items); end

    # Allows sharding of jobs across any number of Redis instances.  All jobs
    # defined within the block will use the given Redis connection pool.
    #
    #   pool = ConnectionPool.new { Redis.new }
    #   Sidekiq::Client.via(pool) do
    #     SomeWorker.perform_async(1,2,3)
    #     SomeOtherWorker.perform_async(1,2,3)
    #   end
    #
    # Generally this is only needed for very large Sidekiq installs processing
    # thousands of jobs per second.  I do not recommend sharding unless
    # you cannot scale any other way (e.g. splitting your app into smaller apps).
    def via(pool); end
  end
end

module Sidekiq::Context
  class << self
    def add(k, v); end
    def current; end
    def with(hash); end
  end
end

Sidekiq::DEFAULTS = T.let(T.unsafe(nil), Hash)
Sidekiq::DEFAULT_WORKER_OPTIONS = T.let(T.unsafe(nil), Hash)

# Allows enumeration of dead jobs within Sidekiq.
class Sidekiq::DeadSet < ::Sidekiq::JobSet
  # @return [DeadSet] a new instance of DeadSet
  def initialize; end

  def kill(message, opts = T.unsafe(nil)); end
  def retry_all; end

  class << self
    def max_jobs; end
    def timeout; end
  end
end

module Sidekiq::ExceptionHandler
  def handle_exception(ex, ctx = T.unsafe(nil)); end
end

class Sidekiq::ExceptionHandler::Logger
  def call(ex, ctx); end
end

module Sidekiq::Extensions
  class << self
    def enable_delay!; end
  end
end

module Sidekiq::Extensions::PsychAutoload
  def resolve_class(klass_name); end
end

Sidekiq::FAKE_INFO = T.let(T.unsafe(nil), Hash)

# Sidekiq::Job is a new alias for Sidekiq::Worker as of Sidekiq 6.3.0.
# Use `include Sidekiq::Job` rather than `include Sidekiq::Worker`.
#
# The term "worker" is too generic and overly confusing, used in several
# different contexts meaning different things. Many people call a Sidekiq
# process a "worker". Some people call the thread that executes jobs a
# "worker". This change brings Sidekiq closer to ActiveJob where your job
# classes extend ApplicationJob.
Sidekiq::Job = Sidekiq::Worker

class Sidekiq::JobLogger
  # @return [JobLogger] a new instance of JobLogger
  def initialize(logger = T.unsafe(nil)); end

  def call(item, queue); end
  def prepare(job_hash, &block); end

  private

  def elapsed(start); end
end

# Encapsulates a pending job within a Sidekiq queue or
# sorted set.
#
# The job should be considered immutable but may be
# removed from the queue via JobRecord#delete.
class Sidekiq::JobRecord
  # @return [JobRecord] a new instance of JobRecord
  def initialize(item, queue_name = T.unsafe(nil)); end

  def [](name); end
  def args; end
  def created_at; end

  # Remove this job from the queue.
  def delete; end

  def display_args; end
  def display_class; end
  def enqueued_at; end
  def error_backtrace; end

  # Returns the value of attribute item.
  def item; end

  def jid; end
  def klass; end
  def latency; end
  def parse(item); end

  # Returns the value of attribute queue.
  def queue; end

  def tags; end

  # Returns the value of attribute value.
  def value; end

  private

  def safe_load(content, default); end
  def uncompress_backtrace(backtrace); end
end

# Automatically retry jobs that fail in Sidekiq.
# Sidekiq's retry support assumes a typical development lifecycle:
#
#   0. Push some code changes with a bug in it.
#   1. Bug causes job processing to fail, Sidekiq's middleware captures
#      the job and pushes it onto a retry queue.
#   2. Sidekiq retries jobs in the retry queue multiple times with
#      an exponential delay, the job continues to fail.
#   3. After a few days, a developer deploys a fix. The job is
#      reprocessed successfully.
#   4. Once retries are exhausted, Sidekiq will give up and move the
#      job to the Dead Job Queue (aka morgue) where it must be dealt with
#      manually in the Web UI.
#   5. After 6 months on the DJQ, Sidekiq will discard the job.
#
# A job looks like:
#
#     { 'class' => 'HardWorker', 'args' => [1, 2, 'foo'], 'retry' => true }
#
# The 'retry' option also accepts a number (in place of 'true'):
#
#     { 'class' => 'HardWorker', 'args' => [1, 2, 'foo'], 'retry' => 5 }
#
# The job will be retried this number of times before giving up. (If simply
# 'true', Sidekiq retries 25 times)
#
# Relevant options for job retries:
#
#  * 'queue' - the queue for the initial job
#  * 'retry_queue' - if job retries should be pushed to a different (e.g. lower priority) queue
#  * 'retry_count' - number of times we've retried so far.
#  * 'error_message' - the message from the exception
#  * 'error_class' - the exception class
#  * 'failed_at' - the first time it failed
#  * 'retried_at' - the last time it was retried
#  * 'backtrace' - the number of lines of error backtrace to store
#
# We don't store the backtrace by default as that can add a lot of overhead
# to the job and everyone is using an error service, right?
#
# The default number of retries is 25 which works out to about 3 weeks
# You can change the default maximum number of retries in your initializer:
#
#   Sidekiq.options[:max_retries] = 7
#
# or limit the number of retries for a particular worker and send retries to
# a low priority queue with:
#
#    class MyWorker
#      include Sidekiq::Worker
#      sidekiq_options retry: 10, retry_queue: 'low'
#    end
class Sidekiq::JobRetry
  include ::Sidekiq::ExceptionHandler
  include ::Sidekiq::Util

  # @return [JobRetry] a new instance of JobRetry
  def initialize(options = T.unsafe(nil)); end

  # The global retry handler requires only the barest of data.
  # We want to be able to retry as much as possible so we don't
  # require the worker to be instantiated.
  def global(jobstr, queue); end

  # The local retry support means that any errors that occur within
  # this block can be associated with the given worker instance.
  # This is required to support the `sidekiq_retries_exhausted` block.
  #
  # Note that any exception from the block is wrapped in the Skip
  # exception so the global block does not reprocess the error.  The
  # Skip exception is unwrapped within Sidekiq::Processor#process before
  # calling the handle_exception handlers.
  def local(worker, jobstr, queue); end

  private

  # Note that +worker+ can be nil here if an error is raised before we can
  # instantiate the worker instance.  All access must be guarded and
  # best effort.
  def attempt_retry(worker, msg, queue, exception); end

  def compress_backtrace(backtrace); end
  def delay_for(worker, count, exception); end

  # @return [Boolean]
  def exception_caused_by_shutdown?(e, checked_causes = T.unsafe(nil)); end

  # Extract message from exception.
  # Set a default if the message raises an error
  def exception_message(exception); end

  def retries_exhausted(worker, msg, exception); end
  def retry_attempts_from(msg_retry, default); end
  def retry_in(worker, count, exception); end
  def send_to_morgue(msg); end
end

Sidekiq::JobRetry::DEFAULT_MAX_RETRY_ATTEMPTS = T.let(T.unsafe(nil), Integer)
class Sidekiq::JobRetry::Handled < ::RuntimeError; end
class Sidekiq::JobRetry::Skip < ::Sidekiq::JobRetry::Handled; end

class Sidekiq::JobSet < ::Sidekiq::SortedSet
  def delete(score, jid); end
  def delete_by_jid(score, jid); end
  def delete_by_value(name, value); end
  def each; end

  # Fetch jobs that match a given time or Range. Job ID is an
  # optional second argument.
  def fetch(score, jid = T.unsafe(nil)); end

  # Find the job with the given JID within this sorted set.
  # This is a slower O(n) operation.  Do not use for app logic.
  def find_job(jid); end

  def schedule(timestamp, message); end
end

module Sidekiq::JobUtil
  # @raise [ArgumentError]
  def normalize_item(item); end

  def normalized_hash(item_class); end

  # These functions encapsulate various job utilities.
  # They must be simple and free from side effects.
  #
  # @raise [ArgumentError]
  def validate(item); end

  private

  # @return [Boolean]
  def json_safe?(item); end
end

Sidekiq::LICENSE = T.let(T.unsafe(nil), String)

class Sidekiq::Logger < ::Logger
  include ::Sidekiq::LoggingUtils

  # @return [Logger] a new instance of Logger
  def initialize(*args, **kwargs); end
end

module Sidekiq::Logger::Formatters; end

class Sidekiq::Logger::Formatters::Base < ::Logger::Formatter
  def ctx; end
  def format_context; end
  def tid; end
end

class Sidekiq::Logger::Formatters::JSON < ::Sidekiq::Logger::Formatters::Base
  def call(severity, time, program_name, message); end
end

class Sidekiq::Logger::Formatters::Pretty < ::Sidekiq::Logger::Formatters::Base
  def call(severity, time, program_name, message); end
end

class Sidekiq::Logger::Formatters::WithoutTimestamp < ::Sidekiq::Logger::Formatters::Pretty
  def call(severity, time, program_name, message); end
end

module Sidekiq::LoggingUtils
  # Redefined to check severity against #level, and thus the thread-local level, rather than +@level+.
  # FIXME: Remove when the minimum Ruby version supports overriding Logger#level.
  def add(severity, message = T.unsafe(nil), progname = T.unsafe(nil), &block); end

  # @return [Boolean]
  def debug?; end

  # @return [Boolean]
  def error?; end

  # @return [Boolean]
  def fatal?; end

  # @return [Boolean]
  def info?; end

  def level; end
  def local_level; end
  def local_level=(level); end

  # Change the thread-local level for the duration of the given block.
  def log_at(level); end

  # @return [Boolean]
  def warn?; end
end

Sidekiq::LoggingUtils::LEVELS = T.let(T.unsafe(nil), Hash)

# The Manager is the central coordination point in Sidekiq, controlling
# the lifecycle of the Processors.
#
# Tasks:
#
# 1. start: Spin up Processors.
# 3. processor_died: Handle job failure, throw away Processor, create new one.
# 4. quiet: shutdown idle Processors.
# 5. stop: hard stop the Processors by deadline.
#
# Note that only the last task requires its own Thread since it has to monitor
# the shutdown process.  The other tasks are performed by other threads.
class Sidekiq::Manager
  include ::Sidekiq::ExceptionHandler
  include ::Sidekiq::Util

  # @raise [ArgumentError]
  # @return [Manager] a new instance of Manager
  def initialize(options = T.unsafe(nil)); end

  # Returns the value of attribute options.
  def options; end

  def processor_died(processor, reason); end
  def processor_stopped(processor); end
  def quiet; end
  def start; end
  def stop(deadline); end

  # @return [Boolean]
  def stopped?; end

  # Returns the value of attribute workers.
  def workers; end

  private

  def hard_shutdown; end
end

# Middleware is code configured to run before/after
# a message is processed.  It is patterned after Rack
# middleware. Middleware exists for the client side
# (pushing jobs onto the queue) as well as the server
# side (when jobs are actually processed).
#
# To add middleware for the client:
#
# Sidekiq.configure_client do |config|
#   config.client_middleware do |chain|
#     chain.add MyClientHook
#   end
# end
#
# To modify middleware for the server, just call
# with another block:
#
# Sidekiq.configure_server do |config|
#   config.server_middleware do |chain|
#     chain.add MyServerHook
#     chain.remove ActiveRecord
#   end
# end
#
# To insert immediately preceding another entry:
#
# Sidekiq.configure_client do |config|
#   config.client_middleware do |chain|
#     chain.insert_before ActiveRecord, MyClientHook
#   end
# end
#
# To insert immediately after another entry:
#
# Sidekiq.configure_client do |config|
#   config.client_middleware do |chain|
#     chain.insert_after ActiveRecord, MyClientHook
#   end
# end
#
# This is an example of a minimal server middleware:
#
# class MyServerHook
#   def call(worker_instance, msg, queue)
#     puts "Before work"
#     yield
#     puts "After work"
#   end
# end
#
# This is an example of a minimal client middleware, note
# the method must return the result or the job will not push
# to Redis:
#
# class MyClientHook
#   def call(worker_class, msg, queue, redis_pool)
#     puts "Before push"
#     result = yield
#     puts "After push"
#     result
#   end
# end
module Sidekiq::Middleware; end

class Sidekiq::Middleware::Chain
  include ::Enumerable

  # @return [Chain] a new instance of Chain
  # @yield [_self]
  # @yieldparam _self [Sidekiq::Middleware::Chain] the object that the method was called on
  def initialize; end

  def add(klass, *args); end
  def clear; end
  def each(&block); end

  # @return [Boolean]
  def empty?; end

  def entries; end

  # @return [Boolean]
  def exists?(klass); end

  def insert_after(oldklass, newklass, *args); end
  def insert_before(oldklass, newklass, *args); end
  def invoke(*args); end
  def prepend(klass, *args); end
  def remove(klass); end
  def retrieve; end

  private

  def initialize_copy(copy); end
end

class Sidekiq::Middleware::Entry
  # @return [Entry] a new instance of Entry
  def initialize(klass, *args); end

  # Returns the value of attribute klass.
  def klass; end

  def make_new; end
end

Sidekiq::NAME = T.let(T.unsafe(nil), String)

# Sidekiq::Process represents an active Sidekiq process talking with Redis.
# Each process has a set of attributes which look like this:
#
# {
#   'hostname' => 'app-1.example.com',
#   'started_at' => <process start time>,
#   'pid' => 12345,
#   'tag' => 'myapp'
#   'concurrency' => 25,
#   'queues' => ['default', 'low'],
#   'busy' => 10,
#   'beat' => <last heartbeat>,
#   'identity' => <unique string identifying the process>,
# }
class Sidekiq::Process
  # @return [Process] a new instance of Process
  def initialize(hash); end

  def [](key); end
  def dump_threads; end
  def identity; end
  def labels; end
  def queues; end
  def quiet!; end
  def stop!; end

  # @return [Boolean]
  def stopping?; end

  def tag; end

  private

  def signal(sig); end
end

# Enumerates the set of Sidekiq processes which are actively working
# right now.  Each process sends a heartbeat to Redis every 5 seconds
# so this set should be relatively accurate, barring network partitions.
#
# Yields a Sidekiq::Process.
class Sidekiq::ProcessSet
  include ::Enumerable

  # @return [ProcessSet] a new instance of ProcessSet
  def initialize(clean_plz = T.unsafe(nil)); end

  # Cleans up dead processes recorded in Redis.
  # Returns the number of processes cleaned.
  def cleanup; end

  def each; end

  # Returns the identity of the current cluster leader or "" if no leader.
  # This is a Sidekiq Enterprise feature, will always return "" in Sidekiq
  # or Sidekiq Pro.
  def leader; end

  # This method is not guaranteed accurate since it does not prune the set
  # based on current heartbeat.  #each does that and ensures the set only
  # contains Sidekiq processes which have sent a heartbeat within the last
  # 60 seconds.
  def size; end

  def total_concurrency; end
  def total_rss; end
  def total_rss_in_kb; end
end

# The Processor is a standalone thread which:
#
# 1. fetches a job from Redis
# 2. executes the job
#   a. instantiate the Worker
#   b. run the middleware chain
#   c. call #perform
#
# A Processor can exit due to shutdown (processor_stopped)
# or due to an error during job execution (processor_died)
#
# If an error occurs in the job execution, the
# Processor calls the Manager to create a new one
# to replace itself and exits.
class Sidekiq::Processor
  include ::Sidekiq::ExceptionHandler
  include ::Sidekiq::Util

  # @return [Processor] a new instance of Processor
  def initialize(mgr, options); end

  # Returns the value of attribute job.
  def job; end

  def kill(wait = T.unsafe(nil)); end
  def start; end
  def terminate(wait = T.unsafe(nil)); end

  # Returns the value of attribute thread.
  def thread; end

  private

  def constantize(str); end
  def dispatch(job_hash, queue, jobstr); end
  def execute_job(worker, cloned_args); end
  def fetch; end
  def get_one; end
  def handle_fetch_exception(ex); end
  def process(work); end
  def process_one; end
  def run; end
  def stats(jobstr, queue); end
end

# Ruby doesn't provide atomic counters out of the box so we'll
# implement something simple ourselves.
# https://bugs.ruby-lang.org/issues/14706
class Sidekiq::Processor::Counter
  # @return [Counter] a new instance of Counter
  def initialize; end

  def incr(amount = T.unsafe(nil)); end
  def reset; end
end

Sidekiq::Processor::FAILURE = T.let(T.unsafe(nil), Sidekiq::Processor::Counter)
Sidekiq::Processor::PROCESSED = T.let(T.unsafe(nil), Sidekiq::Processor::Counter)

# jruby's Hash implementation is not threadsafe, so we wrap it in a mutex here
class Sidekiq::Processor::SharedWorkerState
  # @return [SharedWorkerState] a new instance of SharedWorkerState
  def initialize; end

  def clear; end
  def delete(tid); end
  def dup; end
  def set(tid, hash); end
  def size; end
end

Sidekiq::Processor::WORKER_STATE = T.let(T.unsafe(nil), Sidekiq::Processor::SharedWorkerState)

# Encapsulates a queue within Sidekiq.
# Allows enumeration of all jobs within the queue
# and deletion of jobs.
#
#   queue = Sidekiq::Queue.new("mailer")
#   queue.each do |job|
#     job.klass # => 'MyWorker'
#     job.args # => [1, 2, 3]
#     job.delete if job.jid == 'abcdef1234567890'
#   end
class Sidekiq::Queue
  include ::Enumerable

  # @return [Queue] a new instance of Queue
  def initialize(name = T.unsafe(nil)); end

  def acquire(*args, **_arg1, &block); end
  def block(*args, **_arg1, &block); end
  def block_except(*args, **_arg1, &block); end
  def blocking?(*args, **_arg1, &block); end
  def busy(*args, **_arg1, &block); end
  def clear; end
  def decrease_busy(*args, **_arg1, &block); end
  def each; end
  def explain(*args, **_arg1, &block); end

  # Find the job with the given JID within this queue.
  #
  # This is a slow, inefficient operation.  Do not use under
  # normal conditions.
  def find_job(jid); end

  def increase_busy(*args, **_arg1, &block); end

  # Calculates this queue's latency, the difference in seconds since the oldest
  # job in the queue was enqueued.
  #
  # @return Float
  def latency; end

  def limit(*args, **_arg1, &block); end
  def limit=(*args, **_arg1, &block); end
  def limit_changed?(*args, **_arg1, &block); end
  def local_busy?(*args, **_arg1, &block); end
  def lock; end

  # Returns the value of attribute name.
  def name; end

  def pause(*args, **_arg1, &block); end
  def pause_for_ms(*args, **_arg1, &block); end

  # Sidekiq Pro overrides this
  #
  # @return [Boolean]
  def paused?(*args, **_arg1, &block); end

  def probed(*args, **_arg1, &block); end
  def process_limit(*args, **_arg1, &block); end
  def process_limit=(*args, **_arg1, &block); end
  def release(*args, **_arg1, &block); end
  def remove_locks_except!(*args, **_arg1, &block); end
  def rname; end
  def size; end
  def unblock(*args, **_arg1, &block); end
  def unblocked(*args, **_arg1, &block); end
  def unpause(*args, **_arg1, &block); end
  def ðŸ’£; end

  class << self
    # Return all known queues within Redis.
    def all; end
  end
end

class Sidekiq::Rails < ::Rails::Engine; end

class Sidekiq::Rails::Reloader
  # @return [Reloader] a new instance of Reloader
  def initialize(app = T.unsafe(nil)); end

  def call; end
  def inspect; end
end

class Sidekiq::RedisConnection
  class << self
    def create(options = T.unsafe(nil)); end

    private

    def build_client(options); end
    def client_opts(options); end
    def determine_redis_provider; end
    def log_info(options); end

    # Sidekiq needs a lot of concurrent Redis connections.
    #
    # We need a connection for each Processor.
    # We need a connection for Pro's real-time change listener
    # We need a connection to various features to call Redis every few seconds:
    #   - the process heartbeat.
    #   - enterprise's leader election
    #   - enterprise's cron support
    #
    # @raise [ArgumentError]
    def verify_sizing(size, concurrency); end
  end
end

# Allows enumeration of retries within Sidekiq.
# Based on this, you can search/filter for jobs.  Here's an
# example where I'm selecting all jobs of a certain type
# and deleting them from the retry queue.
#
#   r = Sidekiq::RetrySet.new
#   r.select do |retri|
#     retri.klass == 'Sidekiq::Extensions::DelayedClass' &&
#     retri.args[0] == 'User' &&
#     retri.args[1] == 'setup_new_subscriber'
#   end.map(&:delete)
class Sidekiq::RetrySet < ::Sidekiq::JobSet
  # @return [RetrySet] a new instance of RetrySet
  def initialize; end

  def kill_all; end
  def retry_all; end
end

# This module is part of Sidekiq core and not intended for extensions.
class Sidekiq::RingBuffer
  include ::Enumerable
  extend ::Forwardable

  # @return [RingBuffer] a new instance of RingBuffer
  def initialize(size, default = T.unsafe(nil)); end

  def <<(element); end
  def [](*args, **_arg1, &block); end
  def buffer; end
  def each(*args, **_arg1, &block); end
  def reset(default = T.unsafe(nil)); end
  def size(*args, **_arg1, &block); end
end

module Sidekiq::Scheduled; end

class Sidekiq::Scheduled::Enq
  # @return [Enq] a new instance of Enq
  def initialize; end

  def enqueue_jobs(sorted_sets = T.unsafe(nil)); end
  def terminate; end

  private

  def zpopbyscore(conn, keys: T.unsafe(nil), argv: T.unsafe(nil)); end
end

Sidekiq::Scheduled::Enq::LUA_ZPOPBYSCORE = T.let(T.unsafe(nil), String)

# The Poller checks Redis every N seconds for jobs in the retry or scheduled
# set have passed their timestamp and should be enqueued.  If so, it
# just pops the job back onto its original queue so the
# workers can pick it up like any other job.
class Sidekiq::Scheduled::Poller
  include ::Sidekiq::ExceptionHandler
  include ::Sidekiq::Util

  # @return [Poller] a new instance of Poller
  def initialize; end

  def enqueue; end
  def start; end

  # Shut down this instance, will pause until the thread is dead.
  def terminate; end

  private

  def initial_wait; end

  # We do our best to tune the poll interval to the size of the active Sidekiq
  # cluster.  If you have 30 processes and poll every 15 seconds, that means one
  # Sidekiq is checking Redis every 0.5 seconds - way too often for most people
  # and really bad if the retry or scheduled sets are large.
  #
  # Instead try to avoid polling more than once every 15 seconds.  If you have
  # 30 Sidekiq processes, we'll poll every 30 * 15 or 450 seconds.
  # To keep things statistically random, we'll sleep a random amount between
  # 225 and 675 seconds for each poll or 450 seconds on average.  Otherwise restarting
  # all your Sidekiq processes at the same time will lead to them all polling at
  # the same time: the thundering herd problem.
  #
  # We only do this if poll_interval_average is unset (the default).
  def poll_interval_average; end

  def process_count; end
  def random_poll_interval; end

  # Calculates an average poll interval based on the number of known Sidekiq processes.
  # This minimizes a single point of failure by dispersing check-ins but without taxing
  # Redis if you run many Sidekiq processes.
  def scaled_poll_interval; end

  def wait; end
end

Sidekiq::Scheduled::Poller::INITIAL_WAIT = T.let(T.unsafe(nil), Integer)
Sidekiq::Scheduled::SETS = T.let(T.unsafe(nil), Array)

# Allows enumeration of scheduled jobs within Sidekiq.
# Based on this, you can search/filter for jobs.  Here's an
# example where I'm selecting all jobs of a certain type
# and deleting them from the schedule queue.
#
#   r = Sidekiq::ScheduledSet.new
#   r.select do |scheduled|
#     scheduled.klass == 'Sidekiq::Extensions::DelayedClass' &&
#     scheduled.args[0] == 'User' &&
#     scheduled.args[1] == 'setup_new_subscriber'
#   end.map(&:delete)
class Sidekiq::ScheduledSet < ::Sidekiq::JobSet
  # @return [ScheduledSet] a new instance of ScheduledSet
  def initialize; end
end

# We are shutting down Sidekiq but what about workers that
# are working on some long job?  This error is
# raised in workers that have not finished within the hard
# timeout limit.  This is needed to rollback db transactions,
# otherwise Ruby's Thread#kill will commit.  See #377.
# DO NOT RESCUE THIS ERROR IN YOUR WORKERS
class Sidekiq::Shutdown < ::Interrupt; end

class Sidekiq::SortedEntry < ::Sidekiq::JobRecord
  # @return [SortedEntry] a new instance of SortedEntry
  def initialize(parent, score, item); end

  def add_to_queue; end
  def at; end
  def delete; end

  # @return [Boolean]
  def error?; end

  # Place job in the dead set
  def kill; end

  # Returns the value of attribute parent.
  def parent; end

  def reschedule(at); end
  def retry; end

  # Returns the value of attribute score.
  def score; end

  private

  def remove_job; end
end

class Sidekiq::SortedSet
  include ::Enumerable

  # @return [SortedSet] a new instance of SortedSet
  def initialize(name); end

  def clear; end

  # Returns the value of attribute name.
  def name; end

  def scan(match, count = T.unsafe(nil)); end
  def size; end
  def ðŸ’£; end
end

class Sidekiq::Stats
  # @return [Stats] a new instance of Stats
  def initialize; end

  def dead_size; end
  def default_queue_latency; end
  def enqueued; end
  def failed; end
  def fetch_stats!; end

  # O(1) redis calls
  def fetch_stats_fast!; end

  # O(number of processes + number of queues) redis calls
  def fetch_stats_slow!; end

  def processed; end
  def processes_size; end
  def queues; end
  def reset(*stats); end
  def retry_size; end
  def scheduled_size; end
  def workers_size; end

  private

  def stat(s); end
end

class Sidekiq::Stats::History
  # @raise [ArgumentError]
  # @return [History] a new instance of History
  def initialize(days_previous, start_date = T.unsafe(nil)); end

  def failed; end
  def processed; end

  private

  def date_stat_hash(stat); end
end

class Sidekiq::Stats::Queues
  def lengths; end
end

module Sidekiq::Util
  include ::Sidekiq::ExceptionHandler

  def fire_event(event, options = T.unsafe(nil)); end
  def hostname; end
  def identity; end
  def logger; end
  def process_nonce; end
  def redis(&block); end
  def safe_thread(name, &block); end
  def tid; end

  # Wait for the orblock to be true or the deadline passed.
  def wait_for(deadline, &condblock); end

  def watchdog(last_words); end
end

# hack for quicker development / testing environment #2774
Sidekiq::Util::PAUSE_TIME = T.let(T.unsafe(nil), Float)

Sidekiq::VERSION = T.let(T.unsafe(nil), String)

# The WorkSet stores the work being done by this Sidekiq cluster.
# It tracks the process and thread working on each job.
#
# WARNING WARNING WARNING
#
# This is live data that can change every millisecond.
# If you call #size => 5 and then expect #each to be
# called 5 times, you're going to have a bad time.
#
#    works = Sidekiq::WorkSet.new
#    works.size => 2
#    works.each do |process_id, thread_id, work|
#      # process_id is a unique identifier per Sidekiq process
#      # thread_id is a unique identifier per thread
#      # work is a Hash which looks like:
#      # { 'queue' => name, 'run_at' => timestamp, 'payload' => job_hash }
#      # run_at is an epoch Integer.
#    end
class Sidekiq::WorkSet
  include ::Enumerable

  def each(&block); end

  # Note that #size is only as accurate as Sidekiq's heartbeat,
  # which happens every 5 seconds.  It is NOT real-time.
  #
  # Not very efficient if you have lots of Sidekiq
  # processes but the alternative is a global counter
  # which can easily get out of sync with crashy processes.
  def size; end
end

# Include this module in your worker class and you can easily create
# asynchronous jobs:
#
#   class HardWorker
#     include Sidekiq::Worker
#     sidekiq_options queue: 'critical', retry: 5
#
#     def perform(*args)
#       # do some work
#     end
#   end
#
# Then in your Rails app, you can do this:
#
#   HardWorker.perform_async(1, 2, 3)
#
# Note that perform_async is a class method, perform is an instance method.
#
# Sidekiq::Worker also includes several APIs to provide compatibility with
# ActiveJob.
#
#   class SomeWorker
#     include Sidekiq::Worker
#     queue_as :critical
#
#     def perform(...)
#     end
#   end
#
#   SomeWorker.set(wait_until: 1.hour).perform_async(123)
#
# Note that arguments passed to the job must still obey Sidekiq's
# best practice for simple, JSON-native data types. Sidekiq will not
# implement ActiveJob's more complex argument serialization. For
# this reason, we don't implement `perform_later` as our call semantics
# are very different.
module Sidekiq::Worker
  include ::Sidekiq::Worker::Options

  mixes_in_class_methods ::Sidekiq::Worker::Options::ClassMethods
  mixes_in_class_methods ::Sidekiq::Worker::ClassMethods

  # Returns the value of attribute jid.
  def jid; end

  # Sets the attribute jid
  #
  # @param value the value to set the attribute jid to.
  def jid=(_arg0); end

  def logger; end

  class << self
    # @private
    # @raise [ArgumentError]
    def included(base); end
  end
end

# The Sidekiq testing infrastructure overrides perform_async
# so that it does not actually touch the network.  Instead it
# stores the asynchronous jobs in a per-class array so that
# their presence/absence can be asserted by your tests.
#
# This is similar to ActionMailer's :test delivery_method and its
# ActionMailer::Base.deliveries array.
#
# Example:
#
#   require 'sidekiq/testing'
#
#   assert_equal 0, HardWorker.jobs.size
#   HardWorker.perform_async(:something)
#   assert_equal 1, HardWorker.jobs.size
#   assert_equal :something, HardWorker.jobs[0]['args'][0]
#
#   assert_equal 0, Sidekiq::Extensions::DelayedMailer.jobs.size
#   MyMailer.delay.send_welcome_email('foo@example.com')
#   assert_equal 1, Sidekiq::Extensions::DelayedMailer.jobs.size
#
# You can also clear and drain all workers' jobs:
#
#   assert_equal 0, Sidekiq::Extensions::DelayedMailer.jobs.size
#   assert_equal 0, Sidekiq::Extensions::DelayedModel.jobs.size
#
#   MyMailer.delay.send_welcome_email('foo@example.com')
#   MyModel.delay.do_something_hard
#
#   assert_equal 1, Sidekiq::Extensions::DelayedMailer.jobs.size
#   assert_equal 1, Sidekiq::Extensions::DelayedModel.jobs.size
#
#   Sidekiq::Worker.clear_all # or .drain_all
#
#   assert_equal 0, Sidekiq::Extensions::DelayedMailer.jobs.size
#   assert_equal 0, Sidekiq::Extensions::DelayedModel.jobs.size
#
# This can be useful to make sure jobs don't linger between tests:
#
#   RSpec.configure do |config|
#     config.before(:each) do
#       Sidekiq::Worker.clear_all
#     end
#   end
#
# or for acceptance testing, i.e. with cucumber:
#
#   AfterStep do
#     Sidekiq::Worker.drain_all
#   end
#
#   When I sign up as "foo@example.com"
#   Then I should receive a welcome email to "foo@example.com"
module Sidekiq::Worker::ClassMethods
  def client_push(item); end

  # @raise [ArgumentError]
  def delay(*args); end

  # @raise [ArgumentError]
  def delay_for(*args); end

  # @raise [ArgumentError]
  def delay_until(*args); end

  def perform_async(*args); end

  # +interval+ must be a timestamp, numeric or something that acts
  #   numeric (like an activesupport time interval).
  def perform_at(interval, *args); end

  # Push a large number of jobs to Redis, while limiting the batch of
  # each job payload to 1,000. This method helps cut down on the number
  # of round trips to Redis, which can increase the performance of enqueueing
  # large numbers of jobs.
  #
  # +items+ must be an Array of Arrays.
  #
  # For finer-grained control, use `Sidekiq::Client.push_bulk` directly.
  #
  # Example (3 Redis round trips):
  #
  #     SomeWorker.perform_async(1)
  #     SomeWorker.perform_async(2)
  #     SomeWorker.perform_async(3)
  #
  # Would instead become (1 Redis round trip):
  #
  #     SomeWorker.perform_bulk([[1], [2], [3]])
  def perform_bulk(*args, **kwargs); end

  # +interval+ must be a timestamp, numeric or something that acts
  #   numeric (like an activesupport time interval).
  def perform_in(interval, *args); end

  # Inline execution of job's perform method after passing through Sidekiq.client_middleware and Sidekiq.server_middleware
  def perform_inline(*args); end

  def queue_as(q); end
  def set(options); end

  # Allows customization for this type of Worker.
  # Legal options:
  #
  #   queue - use a named queue for this Worker, default 'default'
  #   retry - enable the RetryJobs middleware for this Worker, *true* to use the default
  #      or *Integer* count
  #   backtrace - whether to save any error backtrace in the retry payload to display in web UI,
  #      can be true, false or an integer number of lines to save, default *false*
  #   pool - use the given Redis connection pool to push this type of job to a given shard.
  #
  # In practice, any option is allowed.  This is the main mechanism to configure the
  # options for a specific job.
  def sidekiq_options(opts = T.unsafe(nil)); end
end

# The Options module is extracted so we can include it in ActiveJob::Base
# and allow native AJs to configure Sidekiq features/internals.
module Sidekiq::Worker::Options
  mixes_in_class_methods ::Sidekiq::Worker::Options::ClassMethods

  class << self
    # @private
    def included(base); end
  end
end

module Sidekiq::Worker::Options::ClassMethods
  def get_sidekiq_options; end
  def sidekiq_class_attribute(*attrs); end

  # Allows customization for this type of Worker.
  # Legal options:
  #
  #   queue - name of queue to use for this job type, default *default*
  #   retry - enable retries for this Worker in case of error during execution,
  #      *true* to use the default or *Integer* count
  #   backtrace - whether to save any error backtrace in the retry payload to display in web UI,
  #      can be true, false or an integer number of lines to save, default *false*
  #
  # In practice, any option is allowed.  This is the main mechanism to configure the
  # options for a specific job.
  def sidekiq_options(opts = T.unsafe(nil)); end

  def sidekiq_retries_exhausted(&block); end
  def sidekiq_retry_in(&block); end
end

Sidekiq::Worker::Options::ClassMethods::ACCESSOR_MUTEX = T.let(T.unsafe(nil), Thread::Mutex)

# This helper class encapsulates the set options for `set`, e.g.
#
#     SomeWorker.set(queue: 'foo').perform_async(....)
class Sidekiq::Worker::Setter
  include ::Sidekiq::JobUtil

  # @return [Setter] a new instance of Setter
  def initialize(klass, opts); end

  def perform_async(*args); end

  # +interval+ must be a timestamp, numeric or something that acts
  #   numeric (like an activesupport time interval).
  def perform_at(interval, *args); end

  def perform_bulk(args, batch_size: T.unsafe(nil)); end

  # +interval+ must be a timestamp, numeric or something that acts
  #   numeric (like an activesupport time interval).
  def perform_in(interval, *args); end

  # Explicit inline execution of a job. Returns nil if the job did not
  # execute, true otherwise.
  def perform_inline(*args); end

  # Explicit inline execution of a job. Returns nil if the job did not
  # execute, true otherwise.
  def perform_sync(*args); end

  def set(options); end

  private

  def at(interval); end
end

# Since "worker" is a nebulous term, we've deprecated the use of this class name.
# Is "worker" a process, a type of job, a thread? Undefined!
# WorkSet better describes the data.
Sidekiq::Workers = Sidekiq::WorkSet
